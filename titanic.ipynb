{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import libraries",
   "id": "fd2bd22a82649ee2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-10T18:25:08.958262Z",
     "start_time": "2025-01-10T18:25:08.951766Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Read Data",
   "id": "23a0c757cd232229"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T18:25:08.978720Z",
     "start_time": "2025-01-10T18:25:08.962763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_data(filepath: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        assert(df.empty != True)\n",
    "        return df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found at {filepath}\\n{e}\")\n",
    "        return None;\n",
    "\n",
    "global separate \n",
    "separate = '\\n********************************\\n'\n",
    "\n",
    "def print_header(message: str) -> None:\n",
    "    \"\"\"\n",
    "    Print a header\n",
    "    'message' should include \\n if needed\n",
    "    :param message: message to be printed\n",
    "    :return: Nothing, purely for o/p\n",
    "    \"\"\"\n",
    "    print(\n",
    "        '\\n',\n",
    "        message,\n",
    "        separate\n",
    "    )"
   ],
   "id": "6692e41d7bb355d1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Explore data",
   "id": "11a5960e63a8212"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T20:23:22.931654Z",
     "start_time": "2025-01-10T20:23:22.921550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def percent_missing(df: pd.DataFrame) -> None:\n",
    "    '''\n",
    "    print the percentage of missing values\n",
    "    per column in the provided dataset\n",
    "    \n",
    "    :param df: pandas dataframe \n",
    "    :return: None\n",
    "    '''\n",
    "    print(round(\\\n",
    "        df.isnull().sum().sort_values(ascending=False) / len(df) * 100\\\n",
    "        , 1))\n",
    "    return\n",
    "\n",
    "\n",
    "def visualize_numerical_data(df: pd.DataFrame, numerical_columns: list) -> None:\n",
    "    '''\n",
    "    visualize the numerical features passed as\n",
    "    'numerical_columns' in the dataset 'df'\n",
    "    histograms / correlation heatmap\n",
    "    \n",
    "    :param df: pandas dataframe\n",
    "    :param numerical_columns: list of numerical interest features\n",
    "    :return: \n",
    "    '''\n",
    "    for feature in numerical_columns:\n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.hist(df[feature])\n",
    "        plt.title(f'{feature}')\n",
    "        plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.heatmap(df[numerical_columns].corr())\n",
    "    \n",
    "    return\n",
    "\n",
    "def visualize_categorical_data(df: pd.DataFrame, categorical_columns: list) -> None:\n",
    "    '''\n",
    "    visualize the categorical features passed as\n",
    "    'categorical_columns' in the dataset 'df'\n",
    "    barplots \n",
    "    \n",
    "    :param df: pandas dataframe \n",
    "    :param categorical_columns: list of categorical interest features \n",
    "    :return: None\n",
    "    '''\n",
    "    for feature in categorical_columns:\n",
    "        plt.figure(figsize=(4,4))\n",
    "        sns.barplot(df[feature].value_counts()).set_title(f'{feature}')\n",
    "        plt.show()\n",
    "    \n",
    "    return \n"
   ],
   "id": "a60dd93c5b40c6fb",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T20:28:13.851794Z",
     "start_time": "2025-01-10T20:28:13.844978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def explore_data(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Explore the titanic dataset itself,\n",
    "    and see about getting some insight\n",
    "    into missing values / correlations between\n",
    "    features\n",
    "    :param df: titanic training dataset, expected\n",
    "    :return: nothing, purely exploratory\n",
    "    \"\"\"\n",
    "\n",
    "    #print .info() to give a sense of where missing values are, \n",
    "    #the number of samples in the dataset, datatypes, etc\n",
    "    print_header(\".info\")\n",
    "    df.info()\n",
    "\n",
    "    #print .describe() to give us some cool stat data from the\n",
    "    #numerical columns in the dataset\n",
    "    print_header(\".describe()\")\n",
    "    df.describe()\n",
    "    \n",
    "    #print the percentage of missing values from each column\n",
    "    print_header('% Missing Values / Features')\n",
    "    percent_missing(df)\n",
    "    #77 percent of cabin information missing, worth filling?\n",
    "    #20 percent of ages missing, need to fill\n",
    "    #barely any embarks missing, can fill with the mode/median\n",
    "    \n",
    "    print_header('Mean Feature / Survived ')\n",
    "    numerical_columns = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "    print(pd.pivot_table(df, index='Survived', values=numerical_columns))\n",
    "    #Those who survived had more than double average fare \n",
    "    #Those who perished were slightly older \n",
    "    \n",
    "    #See average survivability per Pclass\n",
    "    print_header('% Survived / Pclass')\n",
    "    print(round(\n",
    "              df[ ['Pclass', 'Survived'] ]\\\n",
    "                           .groupby('Pclass')\\\n",
    "                           .mean() * 100, 1))\n",
    "    \n",
    "    #see average survivability per Pclass + Sex\n",
    "    print_header('% Survived / Pclass + Sex')\n",
    "    print(round(\n",
    "              df[ ['Pclass', 'Sex', 'Survived'] ]\\\n",
    "                           .groupby( ['Pclass', 'Sex'] )\\\n",
    "                           .mean() * 100, 0) )\n",
    "    #1st Class Females -> 97 percent survived\n",
    "    #2nd Class Females -> 92 percent survived\n",
    "    #3rd Class Females -> 50 percent survived\n",
    "    ##\n",
    "    #1st Class Males -> 37 percent survived\n",
    "    #2nd Class Males -> 16 percent survived\n",
    "    #3rd Class Males -> 14 percent survived\n",
    "    ##\n",
    "    ##so females had wayyy higher chance of surviving than males at any level\n",
    "    ##higher pclass = higher chance\n",
    "\n",
    "    print_header('Passenger Port Embarkation Counts')\n",
    "    print(\n",
    "        \"Passengers Embarked from S :: \", len( df[ (df.Embarked == 'S')] ), '\\n',\n",
    "        \"Passengers Embarked from C :: \", len( df[ (df.Embarked == 'C')] ), '\\n',\n",
    "        \"Passengers Embarked from Q :: \", len( df[ (df.Embarked == 'Q')] ) )\n",
    "\n",
    "    print_header('% Survived / Pclass + Sex + Embarked')\n",
    "    print(round(\n",
    "              df[ ['Pclass', 'Survived', 'Embarked', 'Sex'] ]\\\n",
    "                    .groupby( ['Pclass', 'Embarked', 'Sex'] )\\\n",
    "                    .mean() * 100, 1) )   \n",
    "    #seems as if males who embarked from Q had terrible chances of survival compared to others\n",
    "    \n",
    "    #looked at so far :: Pclass / Sex / Embarked\n",
    "    #need to look at :: Age, Fare, SibSp, Parch"
   ],
   "id": "9f2f8b707790f31a",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T19:21:39.454808Z",
     "start_time": "2025-01-10T19:21:39.436843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def explore_fare(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Investigate the fare feature within the titanic dataset,\n",
    "    and the correlations between the fare and areas of interest\n",
    "    such as average ages, place of embarkation, and passenger class\n",
    "    :param df: titanic training dataset, expected\n",
    "    :return: Nothing, purely exploratory\n",
    "    \"\"\"\n",
    "    print_header(\"Exploring Fare Column\")\n",
    "    #lets print the .describe() for some insight\n",
    "    print_header(\"Fare .describe()\")\n",
    "    print(df['Fare'].describe())\n",
    "    #average = 32\n",
    "    #min = 0\n",
    "    #so lets investigate the 0 cases\n",
    "\n",
    "    print_header('Number of 0-Fare Passengers')\n",
    "    print(len( df[ df.Fare == 0 ] ))\n",
    "    #only 15 cases, lets look at the data\n",
    "\n",
    "    #print(separate, df[ df.Fare == 0 ])\n",
    "    #all males\n",
    "    #all got on at Port S\n",
    "    #traveling alone, no siblings or parents (Sibsp / Parch both 0)\n",
    "    print_header('Average Pclass / Age / Survive of 0-Fare Passengers')\n",
    "    print(df[ df.Fare == 0 ][ ['Pclass', 'Age', 'Survived'] ]\n",
    "                    .mean())         \n",
    "    #Pclass = 1.9\n",
    "    #Age = 35\n",
    "    #Survived = .06\n",
    "    #So on average 2nd Class middle-aged men, and expired \n",
    "    #probably the crew, moving on\n",
    "    \n",
    "    #lets look at cheap fares\n",
    "    print_header('Number of Passengers on Sub-$9 Fare')\n",
    "    sub_9_fare = df['Fare'] < 9.0\n",
    "    print(len( df[ (sub_9_fare) & (exclude_crew) ] ))\n",
    "    #296 people\n",
    "\n",
    "    print_header('Average Numerics for Sub-$9 Passengers')\n",
    "    print(round(\n",
    "              df[ (sub_9_fare) & (exclude_crew)][ ['Pclass', 'Age', 'SibSp', 'Parch', 'Survived'] ]\n",
    "                    .mean(), 1))\n",
    "    #entirely 3rd class\n",
    "    #middle-aged\n",
    "    #almost all died\n",
    "    #lets see the number of children\n",
    "\n",
    "    print_header('Number of children ( < 14 )')\n",
    "    print(len( df[ (sub_9_fare) & (exclude_crew) & (df.Age < 14)] ))\n",
    "    #2\n",
    "\n",
    "    print_header('Number of elders ( > 50 )')\n",
    "    print(len( df[ (sub_9_fare) & (exclude_crew) & (df.Age > 50)] ))\n",
    "    #9\n",
    "    \n",
    "    #so out of 296 sub-9 dollar fares, 285 are between 14 and 50\n",
    "    #how many are missing ages\n",
    "\n",
    "    print_header('Number of missing ages + Sub-$9 Fare')\n",
    "    print(df[ (sub_9_fare) & (exclude_crew) ]['Age'].isnull().sum())\n",
    "    #91 missing ages...\n",
    "\n",
    "    print_header('Average Age + Count  / Pclass + Sex + Port (Sub-$9 Fare)')\n",
    "    print(round(\n",
    "        df[ (sub_9_fare) & (exclude_crew)][ ['Pclass', 'Age', 'Sex', 'Embarked']]\n",
    "                .groupby( ['Pclass', 'Sex', 'Embarked'] )\n",
    "                .agg( ['mean', 'count']), 1))\n",
    "    #can fill 91 missing ages / 177 based on this information\n"
   ],
   "id": "cd156fc0b52a97af",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Data Cleaning",
   "id": "2a36c6b36b1fb48a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T23:50:12.973577Z",
     "start_time": "2025-01-10T23:50:12.965541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fix_ticket(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    fix the ticket column such that it only contains \n",
    "    numbers, no special characters \n",
    "    :param df: pandas dataframe\n",
    "    :return: new dataframe containing adjusted ticket column\n",
    "    '''\n",
    "    df = df.drop('Ticket', axis=1)\n",
    "    #df['Ticket'] = df['Ticket'].str.extract(r'(\\d+)')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fix_cabin(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    fix the cabin column such that it only contains\n",
    "    a single letter indicating deck, or 'N' indicating no cabin\n",
    "    :param df: pandas dataframe\n",
    "    :return: new dataframe containing adjusted cabin column\n",
    "    '''\n",
    "    df['Cabin'] = df['Cabin'].str.extract(r'([A-Za-z])')\n",
    "    df['Cabin'] = df['Cabin'].fillna('n')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_master(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Fill the missing age values where 'Title'\n",
    "    is 'Master'\n",
    "    :param df: pandas dataframe\n",
    "    :return: same dataframe with filled <null> values for 'Master' titles\n",
    "    '''\n",
    "    #define conditions\n",
    "    missing_age = df['Age'].isna()\n",
    "    name_includes_master = df['Title'] == 'Master'\n",
    "    \n",
    "    #calculate the mean age\n",
    "    master_mean = round(\n",
    "        df[name_includes_master]['Age'].mean(), 0)\n",
    "\n",
    "    #fill the instances with the mean\n",
    "    df.loc[ name_includes_master & missing_age, 'Age'] = master_mean\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_sub9(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Fill the msising age values where 'Fare'\n",
    "    is less than $9. Split on male/female\n",
    "    :param df: pandas dataframe\n",
    "    :return: same dataframe with filled <null> values for 'Sub-$9 Fare' Passengers\n",
    "    '''\n",
    "    #define conditions\n",
    "    missing_age = df['Age'].isna()\n",
    "    sub_9_fare = df['Fare'] < 9\n",
    "    exclude_crew = df['Fare'] != 0\n",
    "    males_only = df['Sex'] == 'male'\n",
    "\n",
    "    #Calculate the mean age for males\n",
    "    sub_9_male_mean = round(\n",
    "        df[ (exclude_crew) & (males_only) & (sub_9_fare) ]['Age'].mean()\\\n",
    "        ,0)\n",
    "    \n",
    "    #fill the instances with the mean \n",
    "    df.loc[ (missing_age) & (exclude_crew) & (males_only) & (sub_9_fare), 'Age'] = sub_9_male_mean\n",
    "\n",
    "\n",
    "    #define female conditions\n",
    "    females_only = df['Sex'] == 'female'\n",
    "\n",
    "    #calculate the mean age for females\n",
    "    sub_9_female_mean = round(\n",
    "        df[ (exclude_crew) & (females_only) & (sub_9_fare)]['Age'].mean()\\\n",
    "        ,0)\n",
    "    \n",
    "    #fill the instances with the mean\n",
    "    df.loc[ (missing_age) & (exclude_crew) & (females_only) & (sub_9_fare), 'Age'] = sub_9_female_mean\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fill_crew(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Fill the missing age values where 'Fare'\n",
    "    is equal to 0, indicating a crew member\n",
    "    :param df: pandas dataframe\n",
    "    :return: same dataframe with filled <null> values for crew members\n",
    "    '''\n",
    "    #define conditions\n",
    "    crew_only = df['Fare'] == 0\n",
    "    missing_age = df['Age'].isna()\n",
    "    \n",
    "    #calculate average age\n",
    "    crew_mean = round(\n",
    "        df[ (crew_only) ]['Age'].mean()\\\n",
    "    ,0)\n",
    "    \n",
    "    #fill missing values\n",
    "    df.loc[ (missing_age) & (crew_only), 'Age'] = crew_mean\n",
    "    \n",
    "    return df"
   ],
   "id": "880c9a81f3ba76f1",
   "outputs": [],
   "execution_count": 254
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T23:49:41.398817Z",
     "start_time": "2025-01-10T23:49:41.389641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean Data\n",
    "        - fill missing values\n",
    "        - Drop redundant / insignificant features\n",
    "        -\n",
    "    :param df: uncleaned titanic training set, expected\n",
    "    :return: cleaned titanic training set\n",
    "    \"\"\"\n",
    "    #Drop Passenger ID\n",
    "    #   - no use\n",
    "    df = df.drop('PassengerId', axis=1)\n",
    "    \n",
    "    #Fix Cabin Column\n",
    "    #   -Fill <null> with 'n'\n",
    "    #   -Keep only Deck \n",
    "    df = fix_cabin(df=df)\n",
    "    \n",
    "    \n",
    "    #Fix Ticket Column\n",
    "    #   - only maintain the numerical part \n",
    "    #   - i will fix this later when i realize i need the ticket column for family groups and stuff\n",
    "    df = fix_ticket(df=df)\n",
    "\n",
    "    #Fill Missing Embarked\n",
    "    #   -barely missing any data\n",
    "    #   -filling with mode bc overhead of doing anything else is not worth the information it provides\n",
    "    embarked_mode = df['Embarked'].mode()[0]\n",
    "    df.loc[:, 'Embarked'] = df['Embarked'].fillna(embarked_mode)\n",
    "\n",
    "    #Fill missing ages for 'Master' titles\n",
    "    #   - 'Master' has much younger mean age\n",
    "    #\n",
    "    df = fill_master(df=df)\n",
    "\n",
    "    #Fill missing ages for Sub-$9 Fare Passengers\n",
    "    #   - contains 91 / 177 total <null> ages\n",
    "    df = fill_sub9(df=df)\n",
    "    \n",
    "    #Fill crew\n",
    "    #   - \n",
    "    df = fill_crew(df=df)\n",
    "    \n",
    "    #Fill remaining\n",
    "    df['Age'] = df.groupby( ['Pclass', 'Title', 'Sex'] )['Age']\\\n",
    "                     .transform(lambda x: x.fillna(x.median() ))\n",
    "    \n",
    "    return df\n"
   ],
   "id": "50f182b4520bb41b",
   "outputs": [],
   "execution_count": 252
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Engineering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77f626f84851dc55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T23:02:06.007924Z",
     "start_time": "2025-01-10T23:02:06.001132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_title(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    extract new 'Title' column given df \n",
    "    :param df: pandas dataframe\n",
    "    :return: new dataframe containing new 'Title' column\n",
    "    '''\n",
    "    df['Title'] = df['Name'].str.extract(r',\\s*([A-Za-z]+)')\n",
    "    title_transform = {'Dr': 'Esteemed',\n",
    "                       'Mr': 'Mr',\n",
    "                       'Mme': 'Mr',\n",
    "                       'Ms': 'Miss',\n",
    "                       'Mrs': 'Mrs',\n",
    "                       'Miss': 'Miss',\n",
    "                       'Mlle': 'Miss',\n",
    "                       'Master': 'Master',\n",
    "                       'Jonkheer': 'Crew',\n",
    "                       'Major': 'Crew',\n",
    "                       'Col': 'Crew',\n",
    "                       'Capt': 'Crew', \n",
    "                       'Don': 'Esteemed',\n",
    "                       'Lady': 'Esteemed',\n",
    "                       'Sir': 'Esteemed',\n",
    "                       'the': 'Esteemed',\n",
    "                       'Rev': 'Esteemed'}\n",
    "    df['Title'] = df['Title'].map(title_transform)    \n",
    "\n",
    "    return df\n",
    "\n",
    "def add_familyflag(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    get family size given df\n",
    "    :param df: pandas dataframe\n",
    "    :return: new dataframe containing new 'FamilySize' column\n",
    "    '''\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['LargeFamily'] = df['FamilySize'].apply(lambda x: 1 if x > 4 else 0)\n",
    "    df = df.drop( ['FamilySize', 'SibSp', 'Parch'], axis=1)\n",
    "    \n",
    "    return df"
   ],
   "id": "cac549c7e9a913f0",
   "outputs": [],
   "execution_count": 208
  },
  {
   "cell_type": "code",
   "source": [
    "def data_engineer(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    #Extract the useful part of each Name\n",
    "    #   - 'Title'\n",
    "    #   - 'Drop the 'Name' column\n",
    "    df = extract_title(df=df)  \n",
    "    df = df.drop(columns='Name', axis=1)\n",
    "    \n",
    "    #Get FamilySize\n",
    "    df = add_familyflag(df=df)\n",
    "            \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T23:42:31.985248Z",
     "start_time": "2025-01-10T23:42:31.980957Z"
    }
   },
   "id": "73cc1223c7e50772",
   "outputs": [],
   "execution_count": 239
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Base Model / Model creation\n",
   "id": "34573e3c4f248280"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def all_die_model(df: pd.DataFrame) -> None:\n",
    "    X = pd.DataFrame({'constant': np.ones(df.shape[0])} )\n",
    "    y = df['Survived']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    all_die = LogisticRegression()\n",
    "    \n",
    "    all_die.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = all_die.predict(X_test)\n",
    "    \n",
    "    #Test accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "def women_live_model(df: pd.DataFrame) -> None:\n",
    "    X = pd.DataFrame({'male': (df['Sex'] == 'male').astype(int)})\n",
    "    y = df['Survived']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    women_live = LogisticRegression()\n",
    "    \n",
    "    women_live.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = women_live.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f'Accuracy: {accuracy:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-10T23:02:07.208429Z",
     "start_time": "2025-01-10T23:02:07.202877Z"
    }
   },
   "id": "dc2750d51f4092fb",
   "outputs": [],
   "execution_count": 210
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Putting it all together",
   "id": "8668a8d2ed19b098"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T23:57:27.224994Z",
     "start_time": "2025-01-10T23:57:27.145056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main(argc: int, argv: str) -> None:\n",
    "    #define filepath and read the training data\n",
    "    train_filepath = r'.venv/data/train.csv'\n",
    "    test_filepath = r'.venv/data/test.csv'\n",
    "    \n",
    "    train_data = read_data(train_filepath)\n",
    "    test_data = read_data(test_filepath)\n",
    "    \n",
    "    assert(train_data is not None) \n",
    "    assert(test_data is not None)\n",
    "\n",
    "    train_data['is_train'] = 1\n",
    "    test_data['is_train'] = 0\n",
    "    test_data['Survived'] = np.nan\n",
    "\n",
    "    combined_data = pd.concat( [train_data, test_data], ignore_index=True)\n",
    "\n",
    "    numerical_columns = ['Age', 'Fare', 'SibSp', 'Parch']\n",
    "    categorical_columns = ['Survived', 'Pclass', 'Sex', 'Embarked', 'Ticket', 'Cabin']\n",
    "\n",
    "#    visualize_numerical_data(df=combined_data, numerical_columns=numerical_columns)\n",
    "#    visualize_categorical_data(df=combined_data, categorical_columns=categorical_columns)\n",
    "\n",
    "    #explore the training dataset\n",
    "    explore_data(combined_data)\n",
    "    \n",
    "    combined_data = data_engineer(df=combined_data)\n",
    "    combined_cleaned = clean_data(df=combined_data)\n",
    "    percent_missing(combined_cleaned)\n",
    "    \n",
    "    train_cleaned = combined_cleaned[ combined_cleaned['is_train'] == 1]\n",
    "    test_cleaned = combined_cleaned[ combined_cleaned['is_train'] == 0]\n",
    "    \n",
    "    train_cleaned = train_cleaned.drop('is_train', axis=1)\n",
    "    test_cleaned = test_cleaned.drop('is_train', axis=1)\n",
    "\n",
    "\n",
    "    return \n",
    "main(0, '')"
   ],
   "id": "3b8eb9fd6e947839",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " .info \n",
      "********************************\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  1309 non-null   int64  \n",
      " 1   Survived     891 non-null    float64\n",
      " 2   Pclass       1309 non-null   int64  \n",
      " 3   Name         1309 non-null   object \n",
      " 4   Sex          1309 non-null   object \n",
      " 5   Age          1046 non-null   float64\n",
      " 6   SibSp        1309 non-null   int64  \n",
      " 7   Parch        1309 non-null   int64  \n",
      " 8   Ticket       1309 non-null   object \n",
      " 9   Fare         1308 non-null   float64\n",
      " 10  Cabin        295 non-null    object \n",
      " 11  Embarked     1307 non-null   object \n",
      " 12  is_train     1309 non-null   int64  \n",
      "dtypes: float64(3), int64(5), object(5)\n",
      "memory usage: 133.1+ KB\n",
      "\n",
      " .describe() \n",
      "********************************\n",
      "\n",
      "\n",
      " % Missing Values / Features \n",
      "********************************\n",
      "\n",
      "Cabin          77.5\n",
      "Survived       31.9\n",
      "Age            20.1\n",
      "Embarked        0.2\n",
      "Fare            0.1\n",
      "Sex             0.0\n",
      "Name            0.0\n",
      "Pclass          0.0\n",
      "PassengerId     0.0\n",
      "Ticket          0.0\n",
      "Parch           0.0\n",
      "SibSp           0.0\n",
      "is_train        0.0\n",
      "dtype: float64\n",
      "\n",
      " Mean Feature / Survived  \n",
      "********************************\n",
      "\n",
      "                Age       Fare     Parch     SibSp\n",
      "Survived                                          \n",
      "0.0       30.626179  22.117887  0.329690  0.553734\n",
      "1.0       28.343690  48.395408  0.464912  0.473684\n",
      "\n",
      " % Survived / Pclass \n",
      "********************************\n",
      "\n",
      "        Survived\n",
      "Pclass          \n",
      "1           63.0\n",
      "2           47.3\n",
      "3           24.2\n",
      "\n",
      " % Survived / Pclass + Sex \n",
      "********************************\n",
      "\n",
      "               Survived\n",
      "Pclass Sex             \n",
      "1      female      97.0\n",
      "       male        37.0\n",
      "2      female      92.0\n",
      "       male        16.0\n",
      "3      female      50.0\n",
      "       male        14.0\n",
      "\n",
      " Passenger Port Embarkation Counts \n",
      "********************************\n",
      "\n",
      "Passengers Embarked from S ::  914 \n",
      " Passengers Embarked from C ::  270 \n",
      " Passengers Embarked from Q ::  123\n",
      "\n",
      " % Survived / Pclass + Sex + Embarked \n",
      "********************************\n",
      "\n",
      "                        Survived\n",
      "Pclass Embarked Sex             \n",
      "1      C        female      97.7\n",
      "                male        40.5\n",
      "       Q        female     100.0\n",
      "                male         0.0\n",
      "       S        female      95.8\n",
      "                male        35.4\n",
      "2      C        female     100.0\n",
      "                male        20.0\n",
      "       Q        female     100.0\n",
      "                male         0.0\n",
      "       S        female      91.0\n",
      "                male        15.5\n",
      "3      C        female      65.2\n",
      "                male        23.3\n",
      "       Q        female      72.7\n",
      "                male         7.7\n",
      "       S        female      37.5\n",
      "                male        12.8\n",
      "Survived       31.9\n",
      "Age             0.1\n",
      "Title           0.1\n",
      "Fare            0.1\n",
      "Pclass          0.0\n",
      "Sex             0.0\n",
      "Cabin           0.0\n",
      "Embarked        0.0\n",
      "is_train        0.0\n",
      "LargeFamily     0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 263
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T20:40:29.074684Z",
     "start_time": "2025-01-10T20:40:29.072127Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8cb7d00626b675a7",
   "outputs": [],
   "execution_count": 121
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
